{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bbb081",
   "metadata": {},
   "source": [
    "To obtain the data with the rent prices, we will do web-scrapping from Idealista, a real estate platform that operates primarily in Spain. By scraping data from Idealista, we can access up-to-date information on rental prices across different regions.\n",
    "\n",
    "We encountered some access problems to do web-scrapping directly from the url, so we extracted the html for the tables that contained the information that we wanted as of 29/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e102ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06038a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prices_from_file(html_file_path, city_name):\n",
    "    with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    rows = soup.select(\"tr.table__row\")\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) >= 2:\n",
    "            date = cells[0].get_text(strip=True)\n",
    "            raw_price = cells[1].get_text(strip=True)\n",
    "            match = re.search(r\"[\\d,.]+\", raw_price)\n",
    "            price_text = match.group().replace(\",\", \".\")\n",
    "            data.append({\n",
    "                    \"date\": date,\n",
    "                    \"price\": price_text,\n",
    "                    \"city\": city_name\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4076100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "# Define the directory containing the HTML files\n",
    "directory = os.path.join(path, \"data/html_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e60b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raquel/Documents/master/social_data/social_data_assignments/final_project\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cd34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [table for table in os.listdir(directory) if table.endswith(\".html\")]\n",
    "names = [table.split(\"_\")[2].split(\".\")[0] for table in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0518688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 231 rows from table_prices_palma.html\n",
      "Extracted 231 rows from table_prices_valencia.html\n",
      "Extracted 231 rows from table_prices_barcelona.html\n",
      "Extracted 231 rows from table_prices_madrid.html\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for each file\n",
    "dataframes = []\n",
    "for i, file in enumerate(files):\n",
    "    df = extract_prices_from_file(directory+\"/\"+file, names[i])\n",
    "    print(f\"Extracted {len(df)} rows from {file}\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_all = pd.concat(dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a40af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[df_all[\"price\"] != \".\"]\n",
    "df_all[\"price\"] = df_all[\"price\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267d18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame to a CSV file\n",
    "output_file = os.path.join(path, \"data_clean\", \"prices.csv\")\n",
    "df_all.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
